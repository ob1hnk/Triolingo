using System;
using System.Collections;
using System.Collections.Generic;
using UnityEngine;
using NativeWebSocket;
using System.Text;
using System.Threading.Tasks;

public class SpeechWebSocketClient : MonoBehaviour
{
    private WebSocket ws;
    private string sessionId;
    private int chunkIndex = 0;
    private AudioClip recordingClip;
    private bool isRecording = false;
    private bool isSessionStarted = false; // ì„¸ì…˜ì´ ì‹œì‘ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€
    private string serverUrl = "ws://44.210.134.73:8000/api/v1/ws/speech/v1";

    // ì˜¤ë””ì˜¤ ì„¤ì •
    private int sampleRate = 16000;
    private int channels = 1;
    private int chunkSizeBytes = 8192; // ì•½ 100ms @ 16kHz, 16-bit, mono

    // VAD ì„¤ì •
    private float vadThreshold = 0.0001f; // ìŒì„± ê°ì§€ ì„ê³„ê°’
    private float silenceDuration = 0f; // í˜„ì¬ ë¬´ìŒ ì§€ì† ì‹œê°„
    private float silenceTimeout = 1.5f; // ë¬´ìŒ ì§€ì† ì‹œê°„ ì œí•œ (ì´ˆ) - ì´ ì‹œê°„ ë™ì•ˆ ë¬´ìŒì´ë©´ ì„¸ì…˜ ì¢…ë£Œ
    private bool hasDetectedSpeech = false; // í•œ ë²ˆì´ë¼ë„ ìŒì„±ì´ ê°ì§€ë˜ì—ˆëŠ”ì§€

    // í…ŒìŠ¤íŠ¸/ë””ë²„ê¹… ì„¤ì •
    [Header("í…ŒìŠ¤íŠ¸ ì„¤ì •")]
    [SerializeField] private bool enableDebugLog = true; // ë””ë²„ê·¸ ë¡œê·¸ í™œì„±í™”
    [SerializeField] private float debugLogInterval = 0.5f; // ë””ë²„ê·¸ ë¡œê·¸ ì¶œë ¥ ê°„ê²© (ì´ˆ)
    private float lastDebugLogTime = 0f;

    async void Start()
    {
        await Connect();
    }

    async void OnDestroy()
    {
        await Disconnect();
    }

    async Task Connect()
    {
        ws = new WebSocket(serverUrl);

        ws.OnOpen += () => {
            Debug.Log("WebSocket ì—°ê²°ë¨");
        };

        ws.OnMessage += (bytes) => {
            HandleMessage(Encoding.UTF8.GetString(bytes));
        };

        ws.OnError += (error) => {
            Debug.LogError($"WebSocket ì—ëŸ¬: {error}");
        };

        ws.OnClose += (closeCode) => {
            Debug.Log($"WebSocket ì—°ê²° ì¢…ë£Œ: {closeCode}");
        };

        await ws.Connect();
    }

    async Task Disconnect()
    {
        if (ws != null)
        {
            await ws.Close();
        }
    }

    // ë…¹ìŒ ì‹œì‘ (ì‹œì‘ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ í˜¸ì¶œ)
    public void StartRecording()
    {
        if (isRecording) return;

        // ë§ˆì´í¬ ê¶Œí•œ í™•ì¸
        if (Microphone.devices.Length == 0)
        {
            Debug.LogError("ë§ˆì´í¬ ì¥ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!");
            return;
        }

        Debug.Log($"ë…¹ìŒ ì‹œì‘ - ì‚¬ìš© ì¤‘ì¸ ë§ˆì´í¬: {(Microphone.devices.Length > 0 ? Microphone.devices[0] : "ê¸°ë³¸ ë§ˆì´í¬")}");
        Debug.Log($"ìƒ˜í”Œ ë ˆì´íŠ¸: {sampleRate}Hz, ì±„ë„: {channels}");

        isRecording = true;
        chunkIndex = 0;
        sessionId = Guid.NewGuid().ToString();
        isSessionStarted = false;
        hasDetectedSpeech = false;
        silenceDuration = 0f;
        lastDebugLogTime = 0f;

        // ë§ˆì´í¬ì—ì„œ ë…¹ìŒ ì‹œì‘
        recordingClip = Microphone.Start(null, true, 10, sampleRate);

        if (recordingClip == null)
        {
            Debug.LogError("ë§ˆì´í¬ ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨!");
            isRecording = false;
            return;
        }

        Debug.Log("ë§ˆì´í¬ ë…¹ìŒì´ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.");

        // ì˜¤ë””ì˜¤ ë¶„ì„ ë° ì „ì†¡ ì‹œì‘
        StartCoroutine(ProcessAudioStream());
    }

    // ë…¹ìŒ ì¤‘ì§€ (ìˆ˜ë™ìœ¼ë¡œ ì¤‘ì§€í•  ë•Œë§Œ ì‚¬ìš©, ì¼ë°˜ì ìœ¼ë¡œëŠ” VADê°€ ìë™ìœ¼ë¡œ ì²˜ë¦¬)
    public void StopRecording()
    {
        if (!isRecording) return;

        Debug.Log("ë…¹ìŒ ì¤‘ì§€ ì¤‘...");

        isRecording = false;
        Microphone.End(null);

        // ì„¸ì…˜ì´ ì‹œì‘ë˜ì—ˆë‹¤ë©´ ì¢…ë£Œ
        if (isSessionStarted)
        {
            SendSessionEnd();
        }

        Debug.Log("ë…¹ìŒì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.");
    }

    IEnumerator ProcessAudioStream()
    {
        while (isRecording)
        {
            if (recordingClip != null && Microphone.GetPosition(null) > 0)
            {
                // ìµœê·¼ ì˜¤ë””ì˜¤ ë°ì´í„° ì½ê¸° (ì˜ˆ: ë§ˆì§€ë§‰ 100ms)
                int sampleCount = sampleRate / 10; // 100ms
                float[] samples = new float[sampleCount * channels];
                int micPosition = Microphone.GetPosition(null);
                int startPos = micPosition - sampleCount;

                if (startPos < 0)
                {
                    // ìˆœí™˜ ë²„í¼ ì²˜ë¦¬
                    int firstPart = micPosition;
                    int secondPart = sampleCount - firstPart;

                    float[] firstSamples = new float[firstPart * channels];
                    float[] secondSamples = new float[secondPart * channels];

                    recordingClip.GetData(firstSamples, recordingClip.samples - firstPart);
                    recordingClip.GetData(secondSamples, 0);

                    Array.Copy(firstSamples, 0, samples, 0, firstPart * channels);
                    Array.Copy(secondSamples, 0, samples, firstPart * channels, secondPart * channels);
                }
                else
                {
                    recordingClip.GetData(samples, startPos);
                }

                // ì˜¤ë””ì˜¤ ë ˆë²¨ ë° í†µê³„ ê³„ì‚°
                float currentEnergy = CalculateEnergy(samples);
                float maxAmplitude = GetMaxAmplitude(samples);
                float rms = CalculateRMS(samples);

                // VADë¡œ ìŒì„± ê°ì§€
                bool isSpeech = IsSpeechDetected(samples);

                // ë””ë²„ê·¸ ë¡œê·¸ ì¶œë ¥ (ì„¤ì •ëœ ê°„ê²©ë§ˆë‹¤)
                if (enableDebugLog && Time.time - lastDebugLogTime >= debugLogInterval)
                {
                    LogAudioDebugInfo(micPosition, currentEnergy, maxAmplitude, rms, isSpeech);
                    lastDebugLogTime = Time.time;
                }

                if (isSpeech)
                {
                    // ìŒì„±ì´ ê°ì§€ë¨
                    hasDetectedSpeech = true;
                    silenceDuration = 0f;

                    // ì„¸ì…˜ì´ ì‹œì‘ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì‹œì‘
                    if (!isSessionStarted)
                    {
                        yield return StartCoroutine(SendSessionStart());
                        isSessionStarted = true;
                    }

                    // ì˜¤ë””ì˜¤ ì²­í¬ ì „ì†¡
                    yield return StartCoroutine(SendAudioChunk(samples));
                }
                else
                {
                    // ë¬´ìŒ ê°ì§€
                    if (hasDetectedSpeech && isSessionStarted)
                    {
                        // ì´ë¯¸ ìŒì„±ì´ ê°ì§€ëœ ì ì´ ìˆê³  ì„¸ì…˜ì´ ì‹œì‘ë˜ì—ˆë‹¤ë©´
                        silenceDuration += 0.1f; // 100ms ì¦ê°€

                        // ë¬´ìŒ ì§€ì† ì‹œê°„ ì´ˆê³¼ ì‹œ ì„¸ì…˜ ì¢…ë£Œ
                        if (silenceDuration >= silenceTimeout)
                        {
                            Debug.Log("ë¬´ìŒ ì§€ì† ì‹œê°„ ì´ˆê³¼ - ì„¸ì…˜ ìë™ ì¢…ë£Œ");
                            SendSessionEnd();
                            isSessionStarted = false;
                            hasDetectedSpeech = false;
                            silenceDuration = 0f;
                        }
                    }
                }
            }
            else if (recordingClip == null)
            {
                Debug.LogWarning("recordingClipì´ nullì…ë‹ˆë‹¤!");
            }
            else if (Microphone.GetPosition(null) == 0)
            {
                // ë§ˆì´í¬ê°€ ì•„ì§ ë°ì´í„°ë¥¼ ë°›ì§€ ëª»í•¨
                if (enableDebugLog && Time.time - lastDebugLogTime >= debugLogInterval)
                {
                    Debug.Log("ë§ˆì´í¬ ëŒ€ê¸° ì¤‘... (ì•„ì§ ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹  ì—†ìŒ)");
                    lastDebugLogTime = Time.time;
                }
            }

            yield return new WaitForSeconds(0.1f); // 100msë§ˆë‹¤ ë¶„ì„
        }
    }

    IEnumerator SendSessionStart()
    {
        var startMsg = new {
            type = "session_start",
            session_id = sessionId,
            audio_format = "wav",
            sample_rate = sampleRate,
            channels = channels
        };

        string json = JsonUtility.ToJson(startMsg);
        Debug.Log($"[WS ì¤€ë¹„] session_start payload: {json}");

        yield return StartCoroutine(SendMessageCoroutine("session_start", json));
    }

    IEnumerator SendAudioChunk(float[] samples)
    {
        // WAV í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (PCM ë°ì´í„°)
        byte[] pcmData = ConvertToPCM16(samples);

        // Base64 ì¸ì½”ë”©
        string base64Audio = Convert.ToBase64String(pcmData);
        int currentChunkIndex = chunkIndex++;

        // ì²­í¬ ì „ì†¡
        var chunkMsg = new {
            type = "audio_chunk",
            session_id = sessionId,
            chunk_index = currentChunkIndex,
            audio_data = base64Audio,
            is_last_chunk = false
        };

        string json = JsonUtility.ToJson(chunkMsg);
        Debug.Log($"[WS ì¤€ë¹„] audio_chunk #{currentChunkIndex} | PCM bytes: {pcmData.Length} | Base64 length: {base64Audio.Length}");

        yield return StartCoroutine(SendMessageCoroutine($"audio_chunk #{currentChunkIndex}", json));
    }

    // ê°„ë‹¨í•œ VAD êµ¬í˜„ (ì—ë„ˆì§€ ê¸°ë°˜)
    bool IsSpeechDetected(float[] samples)
    {
        float energy = CalculateEnergy(samples);
        return energy > vadThreshold;
    }

    float CalculateEnergy(float[] samples)
    {
        float sum = 0f;
        foreach (float sample in samples)
        {
            sum += sample * sample;
        }
        return sum / samples.Length;
    }

    // ìµœëŒ€ ì§„í­ ê³„ì‚°
    float GetMaxAmplitude(float[] samples)
    {
        float max = 0f;
        foreach (float sample in samples)
        {
            float abs = Mathf.Abs(sample);
            if (abs > max)
            {
                max = abs;
            }
        }
        return max;
    }

    // RMS (Root Mean Square) ê³„ì‚°
    float CalculateRMS(float[] samples)
    {
        float sum = 0f;
        foreach (float sample in samples)
        {
            sum += sample * sample;
        }
        return Mathf.Sqrt(sum / samples.Length);
    }

    // ì˜¤ë””ì˜¤ ë””ë²„ê·¸ ì •ë³´ ë¡œê·¸ ì¶œë ¥
    void LogAudioDebugInfo(int micPosition, float energy, float maxAmplitude, float rms, bool isSpeech)
    {
        string status = isSpeech ? "ìŒì„± ê°ì§€ë¨ âœ“" : "ë¬´ìŒ";
        string speechIndicator = isSpeech ? "ğŸ”Š" : "ğŸ”‡";
        
        Debug.Log($"[ë§ˆì´í¬ í…ŒìŠ¤íŠ¸] {speechIndicator} {status} | " +
                  $"ìœ„ì¹˜: {micPosition} | " +
                  $"ì—ë„ˆì§€: {energy:F6} | " +
                  $"RMS: {rms:F6} | " +
                  $"ìµœëŒ€ ì§„í­: {maxAmplitude:F6} | " +
                  $"ì„ê³„ê°’: {vadThreshold:F6} | " +
                  $"ì„¸ì…˜ ì‹œì‘ë¨: {isSessionStarted}");
    }

    void SendSessionEnd()
    {
        StartCoroutine(SendSessionEndRoutine());
    }

    IEnumerator SendSessionEndRoutine()
    {
        var endMsg = new {
            type = "session_end",
            session_id = sessionId
        };

        string json = JsonUtility.ToJson(endMsg);
        Debug.Log($"[WS ì¤€ë¹„] session_end payload: {json}");

        yield return StartCoroutine(SendMessageCoroutine("session_end", json));
    }

    void HandleMessage(string message)
    {
        var response = JsonUtility.FromJson<WebSocketResponse>(message);

        switch (response.type)
        {
            case "ack":
                Debug.Log($"ACK ìˆ˜ì‹ : {response.message}");
                break;

            case "processing":
                Debug.Log($"ì²˜ë¦¬ ì¤‘: {response.status}");
                break;

            case "result":
                Debug.Log($"ê²°ê³¼ ìˆ˜ì‹ :");
                Debug.Log($"  ì¸ì‹: {response.transcription}");
                Debug.Log($"  ì‘ë‹µ: {response.text}");
                OnResultReceived(response.text, response.transcription);
                break;

            case "error":
                Debug.LogError($"ì—ëŸ¬: {response.error_code} - {response.error_message}");
                OnErrorReceived(response.error_code, response.error_message);
                break;
        }
    }

    IEnumerator SendMessageCoroutine(string messageLabel, string json)
    {
        if (ws == null)
        {
            Debug.LogError($"[WS ì˜¤ë¥˜] {messageLabel} ì „ì†¡ ì‹¤íŒ¨ - WebSocket ì¸ìŠ¤í„´ìŠ¤ê°€ null ì…ë‹ˆë‹¤.");
            yield break;
        }

        if (ws.State != WebSocketState.Open)
        {
            Debug.LogWarning($"[WS ê²½ê³ ] {messageLabel} ì „ì†¡ ì‹¤íŒ¨ - í˜„ì¬ ìƒíƒœ: {ws.State}");
            yield break;
        }

        Debug.Log($"[WS->Server] {messageLabel} ì „ì†¡ ì‹œì‘");

        var sendTask = ws.SendText(json);
        while (!sendTask.IsCompleted)
        {
            yield return null;
        }

        if (sendTask.IsFaulted)
        {
            Debug.LogError($"[WS ì˜¤ë¥˜] {messageLabel} ì „ì†¡ ì¤‘ ì˜ˆì™¸: {sendTask.Exception}");
        }
        else if (sendTask.IsCanceled)
        {
            Debug.LogWarning($"[WS ê²½ê³ ] {messageLabel} ì „ì†¡ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.");
        }
        else
        {
            Debug.Log($"[WS->Server] {messageLabel} ì „ì†¡ ì™„ë£Œ");
        }
    }

    // Float ë°°ì—´ì„ 16-bit PCM ë°”ì´íŠ¸ ë°°ì—´ë¡œ ë³€í™˜
    byte[] ConvertToPCM16(float[] samples)
    {
        byte[] pcmData = new byte[samples.Length * 2];

        for (int i = 0; i < samples.Length; i++)
        {
            // -1.0 ~ 1.0 ë²”ìœ„ë¥¼ -32768 ~ 32767ë¡œ ë³€í™˜
            short sample = (short)(samples[i] * 32767f);
            pcmData[i * 2] = (byte)(sample & 0xFF);
            pcmData[i * 2 + 1] = (byte)((sample >> 8) & 0xFF);
        }

        return pcmData;
    }

    // ê²°ê³¼ ìˆ˜ì‹  ì½œë°±
    public event Action<string, string> OnResultReceived;

    // ì—ëŸ¬ ìˆ˜ì‹  ì½œë°±
    public event Action<string, string> OnErrorReceived;
}

// ì‘ë‹µ ë©”ì‹œì§€ êµ¬ì¡°ì²´
[Serializable]
public class WebSocketResponse
{
    public string type;
    public string session_id;
    public string message;
    public int? chunk_index;
    public string status;
    public float? progress;
    public string text;
    public string transcription;
    public string error_code;
    public string error_message;
}
